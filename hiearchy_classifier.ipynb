{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eceb2f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import splitfolders\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import imagefolder\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516aa771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    \"\"\"Set random seed.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed to be used.\n",
    "        deterministic (bool): Whether to set the deterministic option for\n",
    "            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`\n",
    "            to True and `torch.backends.cudnn.benchmark` to False.\n",
    "            Default: False.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ad4445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = 'C:\\\\Users\\\\Oge\\\\Documents\\\\Work\\\\Official\\\\hierachical_classifier\\\\data\\\\val' \n",
    "imgfoldermap = imagefolder.HeirarchicalLabelMap(root_folder, level_names=['category', 'subcategory', 'item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f87094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Golden-Delicious': 0,\n",
       " 'Granny-Smith': 1,\n",
       " 'Pink-Lady': 2,\n",
       " 'Royal-Gala': 3,\n",
       " 'Cantaloupe': 4,\n",
       " 'Galia-Melon': 5,\n",
       " 'Honeydew-Melon': 6,\n",
       " 'Watermelon': 7,\n",
       " 'Conference': 8,\n",
       " 'Bravo-Apple-Juice': 9,\n",
       " 'Bravo-Orange-Juice': 10,\n",
       " 'God-Morgon-Apple-Juice': 11,\n",
       " 'God-Morgon-Orange-Juice': 12,\n",
       " 'God-Morgon-Orange-Red-Grapefruit-Juice': 13,\n",
       " 'God-Morgon-Red-Grapefruit-Juice': 14,\n",
       " 'Arla-Ecological-Medium-Fat-Milk': 15,\n",
       " 'Arla-Medium-Fat-Milk': 16,\n",
       " 'Arla-Standard-Milk': 17,\n",
       " 'Garant-Ecological-Medium-Fat-Milk': 18,\n",
       " 'Garant-Ecological-Standard-Milk': 19,\n",
       " 'Oatly-Oat-Milk': 20,\n",
       " 'Oatly-Natural-Oatghurt': 21,\n",
       " 'Arla-Sour-Cream': 22,\n",
       " 'Alpro-Blueberry-Soyghurt': 23,\n",
       " 'Alpro-Vanilla-Soyghurt': 24,\n",
       " 'Arla-Mild-Vanilla-Yoghurt': 25,\n",
       " 'Valio-Vanilla-Yoghurt': 26,\n",
       " 'Yoggi-Strawberry-Yoghurt': 27,\n",
       " 'Yoggi-Vanilla-Yoghurt': 28,\n",
       " 'Yellow-Onion': 29,\n",
       " 'Orange-Bell-Pepper': 30,\n",
       " 'Red-Bell-Pepper': 31,\n",
       " 'Yellow-Bell-Pepper': 32,\n",
       " 'Floury-Potato': 33,\n",
       " 'Sweet-Potato': 34,\n",
       " 'Beef-Tomato': 35,\n",
       " 'Vine-Tomato': 36}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgfoldermap.leaf_class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44bf1604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class HierarchicalDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None, labelmap=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.leaf_paths = labelmap.get_leaf_paths()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.labelmap = labelmap\n",
    "        self.dataset = self.make_dataset()\n",
    "        \n",
    "        \n",
    "    def make_dataset(self, extensions = ['.jpg', '.jpeg'], is_valid_file = None):\n",
    "        \"\"\"Generates a list of samples of a form (path_to_sample, class).\n",
    "\n",
    "        See :class:`DatasetFolder` for details.\n",
    "\n",
    "        \"\"\"\n",
    "        class_to_idx = self.labelmap.leaf_class_labels\n",
    "\n",
    "        '''\n",
    "        both_none = extensions is None and is_valid_file is None\n",
    "        both_something = extensions is not None and is_valid_file is not None\n",
    "        if both_none or both_something:\n",
    "            raise ValueError(\"Both extensions and is_valid_file cannot be None or not None at the same time\")\n",
    "\n",
    "        if extensions is not None:\n",
    "            def is_valid_file(x: str) -> bool:\n",
    "                return has_file_allowed_extension(x, cast(Tuple[str, ...], extensions))\n",
    "\n",
    "        is_valid_file = cast(Callable[[str], bool], is_valid_file)\n",
    "        '''\n",
    "\n",
    "        instances = []\n",
    "        available_classes = set()\n",
    "        for leaf_path in self.leaf_paths:\n",
    "            if not os.path.isdir(leaf_path):\n",
    "                continue\n",
    "            target_class = os.path.basename(leaf_path)\n",
    "            class_index = class_to_idx[target_class]\n",
    "\n",
    "            for root, _, filenames in sorted(os.walk(leaf_path, followlinks=False)):\n",
    "                for fname in sorted(filenames):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    extension = (os.path.splitext(fname)[1]).lower().strip()\n",
    "                    #TODO redo to is valid file\n",
    "                    if os.path.isfile(path) and extension in extensions:\n",
    "                        item = path, class_index\n",
    "                        instances.append(item)\n",
    "\n",
    "                        if target_class not in available_classes:\n",
    "                            available_classes.add(target_class)\n",
    "\n",
    "        empty_classes = set(class_to_idx.keys()) - available_classes\n",
    "\n",
    "        if empty_classes:\n",
    "            msg = f\"Found not valid file for the classes {', '.join(sorted(empty_classes))}. \"\n",
    "            if extensions is not None:\n",
    "                msg += f\"Supported extensions are: {', '.join(extensions)}\"\n",
    "            raise FileNotFoundError(msg)\n",
    "\n",
    "        return np.array(instances)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, indices = self.dataset[idx]\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        #sample = {'image': image, 'label': indices}\n",
    "\n",
    "        return image, int(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed934290",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "tr_transform = transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "\n",
    "begin = time.time()\n",
    "tr_dataset = HierarchicalDataset(root_folder, labelmap=imgfoldermap, transform=tr_transform)\n",
    "end = time.time() - begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "624f9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(tr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35288cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b= tr_dataset[5]\n",
    "a.shape,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6717994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 8\n",
    "workers = 0\n",
    "pinmemory = True\n",
    "train_loader = torch.utils.data.DataLoader(tr_dataset, batch_size=batchsize, num_workers=workers, shuffle=True, pin_memory=pinmemory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78941a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleDict(\n",
      "  (root): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (category_Fruit_1): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (category_Packages_1): Linear(in_features=512, out_features=7, bias=True)\n",
      "  (category_Vegetables_1): Linear(in_features=512, out_features=4, bias=True)\n",
      "  (subcategory_Apple_2): Linear(in_features=512, out_features=4, bias=True)\n",
      "  (subcategory_Melon_2): Linear(in_features=512, out_features=4, bias=True)\n",
      "  (subcategory_Pear_2): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (subcategory_Juice_2): Linear(in_features=512, out_features=6, bias=True)\n",
      "  (subcategory_Milk_2): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (subcategory_Oat-Milk_2): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (subcategory_Oatghurt_2): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (subcategory_Sour-Cream_2): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (subcategory_Soyghurt_2): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (subcategory_Yoghurt_2): Linear(in_features=512, out_features=4, bias=True)\n",
      "  (subcategory_Onion_2): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (subcategory_Pepper_2): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (subcategory_Potato_2): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (subcategory_Tomato_2): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=44944, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (hsoftmax): HierarchicalSoftmax(\n",
      "    (module_dict): ModuleDict(\n",
      "      (root): Linear(in_features=512, out_features=3, bias=True)\n",
      "      (category_Fruit_1): Linear(in_features=512, out_features=3, bias=True)\n",
      "      (category_Packages_1): Linear(in_features=512, out_features=7, bias=True)\n",
      "      (category_Vegetables_1): Linear(in_features=512, out_features=4, bias=True)\n",
      "      (subcategory_Apple_2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      (subcategory_Melon_2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      (subcategory_Pear_2): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (subcategory_Juice_2): Linear(in_features=512, out_features=6, bias=True)\n",
      "      (subcategory_Milk_2): Linear(in_features=512, out_features=5, bias=True)\n",
      "      (subcategory_Oat-Milk_2): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (subcategory_Oatghurt_2): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (subcategory_Sour-Cream_2): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (subcategory_Soyghurt_2): Linear(in_features=512, out_features=2, bias=True)\n",
      "      (subcategory_Yoghurt_2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      (subcategory_Onion_2): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (subcategory_Pepper_2): Linear(in_features=512, out_features=3, bias=True)\n",
      "      (subcategory_Potato_2): Linear(in_features=512, out_features=2, bias=True)\n",
      "      (subcategory_Tomato_2): Linear(in_features=512, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "outsize = 512\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(44944, 2048)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, outsize)\n",
    "        self.hsoftmax = imagefolder.HierarchicalSoftmax(labelmap=imgfoldermap, input_size=outsize, level_weights=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.hsoftmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c04f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8df327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 10 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "#set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "criterion = criterion = torch.nn.NLLLoss() # nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f331e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4707761c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec627f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.9694; Accuracy: 0.0486\n",
      "\n",
      "Loss: 3.2318; Accuracy: 0.0541\n",
      "\n",
      "Loss: 2.9906; Accuracy: 0.0811\n",
      "\n",
      "Loss: 3.0086; Accuracy: 0.0919\n",
      "\n",
      "Loss: 2.9368; Accuracy: 0.0649\n",
      "\n",
      "Loss: 2.7165; Accuracy: 0.1405\n",
      "\n",
      "Loss: 2.5776; Accuracy: 0.1784\n",
      "\n",
      "Loss: 2.6657; Accuracy: 0.1189\n",
      "\n",
      "Loss: 2.5021; Accuracy: 0.2054\n",
      "\n",
      "Loss: 2.3053; Accuracy: 0.2757\n",
      "\n",
      "Loss: 2.8759; Accuracy: 0.1838\n",
      "\n",
      "Loss: 2.9655; Accuracy: 0.1297\n",
      "\n",
      "Loss: 2.6669; Accuracy: 0.1676\n",
      "\n",
      "Loss: 2.4890; Accuracy: 0.2108\n",
      "\n",
      "Loss: 2.5459; Accuracy: 0.2162\n",
      "\n",
      "Loss: 2.4466; Accuracy: 0.2541\n",
      "\n",
      "Loss: 2.3121; Accuracy: 0.2162\n",
      "\n",
      "Loss: 2.1869; Accuracy: 0.2486\n",
      "\n",
      "Loss: 2.3627; Accuracy: 0.2541\n",
      "\n",
      "Loss: 2.1054; Accuracy: 0.3297\n",
      "\n",
      "Loss: 2.1522; Accuracy: 0.3189\n",
      "\n",
      "Loss: 2.3924; Accuracy: 0.2432\n",
      "\n",
      "Loss: 2.1332; Accuracy: 0.3459\n",
      "\n",
      "Loss: 2.1435; Accuracy: 0.3459\n",
      "\n",
      "Loss: 2.0042; Accuracy: 0.3351\n",
      "\n",
      "Loss: 1.8869; Accuracy: 0.4432\n",
      "\n",
      "Loss: 1.9528; Accuracy: 0.4162\n",
      "\n",
      "Loss: 1.9177; Accuracy: 0.4378\n",
      "\n",
      "Loss: 2.3964; Accuracy: 0.3730\n",
      "\n",
      "Loss: 1.6884; Accuracy: 0.4432\n",
      "\n",
      "Loss: 2.0604; Accuracy: 0.3676\n",
      "\n",
      "Loss: 2.2191; Accuracy: 0.3081\n",
      "\n",
      "Loss: 2.4013; Accuracy: 0.2865\n",
      "\n",
      "Loss: 2.1973; Accuracy: 0.3189\n",
      "\n",
      "Loss: 1.7425; Accuracy: 0.4378\n",
      "\n",
      "Loss: 2.0189; Accuracy: 0.3568\n",
      "\n",
      "Loss: 1.6150; Accuracy: 0.5189\n",
      "\n",
      "Loss: 1.7104; Accuracy: 0.3946\n",
      "\n",
      "Loss: 2.0184; Accuracy: 0.4054\n",
      "\n",
      "Loss: 1.6854; Accuracy: 0.4324\n",
      "\n",
      "Loss: 1.7926; Accuracy: 0.4324\n",
      "\n",
      "Loss: 1.5502; Accuracy: 0.5243\n",
      "\n",
      "Loss: 1.5011; Accuracy: 0.5027\n",
      "\n",
      "Loss: 1.6113; Accuracy: 0.5135\n",
      "\n",
      "Loss: 1.5153; Accuracy: 0.5027\n",
      "\n",
      "Loss: 1.4348; Accuracy: 0.5351\n",
      "\n",
      "Loss: 1.5396; Accuracy: 0.5514\n",
      "\n",
      "Loss: 1.5710; Accuracy: 0.4649\n",
      "\n",
      "Loss: 1.3995; Accuracy: 0.5351\n",
      "\n",
      "Loss: 1.4585; Accuracy: 0.4865\n",
      "\n",
      "Loss: 1.2762; Accuracy: 0.5838\n",
      "\n",
      "Loss: 1.2496; Accuracy: 0.5892\n",
      "\n",
      "Loss: 1.3854; Accuracy: 0.5189\n",
      "\n",
      "Loss: 1.2914; Accuracy: 0.5838\n",
      "\n",
      "Loss: 1.3061; Accuracy: 0.5838\n",
      "\n",
      "Loss: 1.4151; Accuracy: 0.5459\n",
      "\n",
      "Loss: 1.6520; Accuracy: 0.5081\n",
      "\n",
      "Loss: 1.7205; Accuracy: 0.5081\n",
      "\n",
      "Loss: 1.2655; Accuracy: 0.6054\n",
      "\n",
      "Loss: 1.2897; Accuracy: 0.6162\n",
      "\n",
      "Loss: 1.4838; Accuracy: 0.5622\n",
      "\n",
      "Loss: 1.3993; Accuracy: 0.5892\n",
      "\n",
      "Loss: 1.3573; Accuracy: 0.6054\n",
      "\n",
      "Loss: 1.0123; Accuracy: 0.6595\n",
      "\n",
      "Loss: 1.1164; Accuracy: 0.6432\n",
      "\n",
      "Loss: 1.2584; Accuracy: 0.5297\n",
      "\n",
      "Loss: 1.1958; Accuracy: 0.6432\n",
      "\n",
      "Loss: 1.4984; Accuracy: 0.5459\n",
      "\n",
      "Loss: 1.2518; Accuracy: 0.6649\n",
      "\n",
      "Loss: 1.8487; Accuracy: 0.5459\n",
      "\n",
      "Loss: 1.2307; Accuracy: 0.5784\n",
      "\n",
      "Loss: 1.4115; Accuracy: 0.5892\n",
      "\n",
      "Loss: 1.3657; Accuracy: 0.5730\n",
      "\n",
      "Loss: 1.2739; Accuracy: 0.6108\n",
      "\n",
      "Loss: 1.2089; Accuracy: 0.6378\n",
      "\n",
      "Loss: 1.1615; Accuracy: 0.6703\n",
      "\n",
      "Loss: 1.1126; Accuracy: 0.7027\n",
      "\n",
      "Loss: 1.1549; Accuracy: 0.6270\n",
      "\n",
      "Loss: 1.0934; Accuracy: 0.6649\n",
      "\n",
      "Loss: 1.0233; Accuracy: 0.6973\n",
      "\n",
      "Loss: 1.0254; Accuracy: 0.6703\n",
      "\n",
      "Loss: 1.0873; Accuracy: 0.7243\n",
      "\n",
      "Loss: 1.3293; Accuracy: 0.6595\n",
      "\n",
      "Loss: 1.0147; Accuracy: 0.6811\n",
      "\n",
      "Loss: 1.2325; Accuracy: 0.6324\n",
      "\n",
      "Loss: 0.8720; Accuracy: 0.7784\n",
      "\n",
      "Loss: 0.8622; Accuracy: 0.7189\n",
      "\n",
      "Loss: 0.9963; Accuracy: 0.6973\n",
      "\n",
      "Loss: 0.9938; Accuracy: 0.7135\n",
      "\n",
      "Loss: 1.0417; Accuracy: 0.7027\n",
      "\n",
      "Loss: 0.7473; Accuracy: 0.7838\n",
      "\n",
      "Loss: 1.0523; Accuracy: 0.6649\n",
      "\n",
      "Loss: 0.9253; Accuracy: 0.6973\n",
      "\n",
      "Loss: 0.8743; Accuracy: 0.7514\n",
      "\n",
      "Loss: 0.9808; Accuracy: 0.7081\n",
      "\n",
      "Loss: 1.2671; Accuracy: 0.6270\n",
      "\n",
      "Loss: 1.0551; Accuracy: 0.6973\n",
      "\n",
      "Loss: 0.7442; Accuracy: 0.7838\n",
      "\n",
      "Loss: 1.1367; Accuracy: 0.7405\n",
      "\n",
      "Loss: 1.1788; Accuracy: 0.6757\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs[1]\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        #class_probs_batch = [F.softmax(output, dim=0) for output in outputs]\n",
    "        #outputs = F.log_softmax(outputs, dim=0)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_correct += torch.sum(preds == labels)\n",
    "        \n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    epoch_accuracy = running_correct.double() / dataset_size\n",
    "        \n",
    "    print(f'Loss: {epoch_loss:.4f}; Accuracy: {epoch_accuracy:.4f}')\n",
    "    print('')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f4e7e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc91b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(inputs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da7ad90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fruit', 'Apple', 'Pink-Lady']\n",
      "['Packages', 'Juice', 'God-Morgon-Orange-Juice']\n",
      "['Packages', 'Oatghurt', 'Oatly-Natural-Oatghurt']\n",
      "['Packages', 'Juice', 'God-Morgon-Orange-Juice']\n",
      "['Packages', 'Yoghurt', 'Yoggi-Strawberry-Yoghurt']\n",
      "['Packages', 'Milk', 'Garant-Ecological-Medium-Fat-Milk']\n",
      "['Packages', 'Milk', 'Arla-Ecological-Medium-Fat-Milk']\n",
      "['Packages', 'Milk', 'Arla-Medium-Fat-Milk']\n"
     ]
    }
   ],
   "source": [
    "logits = torch.exp(outputs[0])\n",
    "#print(logits)\n",
    "h = imgfoldermap.get_heirarchies(logits)\n",
    "#print(h)\n",
    "for l in h:\n",
    "    print(imgfoldermap.get_heirarchy_label(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3df5b88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2, 10, 21, 12, 27, 18, 15, 15])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c2abaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Golden-Delicious': 0,\n",
       " 'Granny-Smith': 1,\n",
       " 'Pink-Lady': 2,\n",
       " 'Royal-Gala': 3,\n",
       " 'Cantaloupe': 4,\n",
       " 'Galia-Melon': 5,\n",
       " 'Honeydew-Melon': 6,\n",
       " 'Watermelon': 7,\n",
       " 'Conference': 8,\n",
       " 'Bravo-Apple-Juice': 9,\n",
       " 'Bravo-Orange-Juice': 10,\n",
       " 'God-Morgon-Apple-Juice': 11,\n",
       " 'God-Morgon-Orange-Juice': 12,\n",
       " 'God-Morgon-Orange-Red-Grapefruit-Juice': 13,\n",
       " 'God-Morgon-Red-Grapefruit-Juice': 14,\n",
       " 'Arla-Ecological-Medium-Fat-Milk': 15,\n",
       " 'Arla-Medium-Fat-Milk': 16,\n",
       " 'Arla-Standard-Milk': 17,\n",
       " 'Garant-Ecological-Medium-Fat-Milk': 18,\n",
       " 'Garant-Ecological-Standard-Milk': 19,\n",
       " 'Oatly-Oat-Milk': 20,\n",
       " 'Oatly-Natural-Oatghurt': 21,\n",
       " 'Arla-Sour-Cream': 22,\n",
       " 'Alpro-Blueberry-Soyghurt': 23,\n",
       " 'Alpro-Vanilla-Soyghurt': 24,\n",
       " 'Arla-Mild-Vanilla-Yoghurt': 25,\n",
       " 'Valio-Vanilla-Yoghurt': 26,\n",
       " 'Yoggi-Strawberry-Yoghurt': 27,\n",
       " 'Yoggi-Vanilla-Yoghurt': 28,\n",
       " 'Yellow-Onion': 29,\n",
       " 'Orange-Bell-Pepper': 30,\n",
       " 'Red-Bell-Pepper': 31,\n",
       " 'Yellow-Bell-Pepper': 32,\n",
       " 'Floury-Potato': 33,\n",
       " 'Sweet-Potato': 34,\n",
       " 'Beef-Tomato': 35,\n",
       " 'Vine-Tomato': 36}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgfoldermap.leaf_class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf49fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
